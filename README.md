# GraphPFound

## 1. Цель проекта

**Главная цель:**  
смоделировать поведение пользователя в выдаче «2 столбца × N полок» через HMM/цепь Маркова, ввести и считать метрику `PFound` / `GPFound` для такой выдачи и связать её:

- с ручной (синтетической) релевантностью;
- с ML/DL-моделью релевантности, обученной на реальных данных (например, Amazon).

*Замечание: проект ориентирован на формальное описание поведения пользователя и связь этой модели с метриками качества ранжирования.*

**Дополнительные цели:**

- Научиться программно считать `P_look` (вероятность просмотра полки) и `PFound`.
- Исследовать, как:
  - перестановка карточек (ранжирование),
  - качество модели релевантности  
  влияют на `PFound`.
- Реализовать генерацию синтетических запросов (query) и логов поведения пользователя.

---

## 2. Формальная модель выдачи (query)

### 2.1. Геометрия выдачи

Выдача по запросу — это решётка размером `2 × N`:

- 2 столбца (левый и правый);
- `N` строк, каждая строка — это полка.

Полка с индексом `i` содержит две карточки:

- `(i, 0)` — левая карточка;
- `(i, 1)` — правая карточка.

`Query` = последовательность полок:

`Shelf_1, Shelf_2, ..., Shelf_N`.

### 2.2. Структура данных для карточки

Для каждой карточки `(i, pos)` в датасете храним:

- `query_id` — идентификатор запроса;
- `shelf_id = i` — номер полки;
- `position ∈ {0,1}` — левый/правый столбец;
- `relevance` — релевантность (числовая метка или скор):
  - сначала задаётся вручную (синтетика);
  - затем предсказывается моделью;
- `color` — категориальный признак (тип оформления / цвет);
- `text_features` — текстовые признаки (сырые тексты или эмбеддинги);
- `clicked ∈ {0,1}` — был ли клик;
- `purchased ∈ {0,1}` — была ли покупка.

**Задачи блока:**

- Определить формат хранения данных (например, `pandas.DataFrame` + схема).
- Формализовать типы признаков:
  - какие текстовые признаки используются (title, description, embedding);
  - какие категориальные и числовые признаки.
- Определить формат связи:
  - таблица карточек;
  - таблица запросов (мета-информация о query: длина, id и т.д.).

---

## 3. Модель поведения пользователя: скрытая цепь Маркова (HMM)

### 3.1. Скрытые состояния (уровень полок)

Скрытые состояния соответствуют полкам выдачи:

- полки `i = 1, ..., N`.

Для полки `i` вводим величину:

- `P_look(i)` — вероятность того, что пользователь дойдёт до полки `i` и будет её просматривать.

Интуитивно: полка — это скрытое состояние, а `P_look(i)` — “масса вероятности” этого состояния.

Базово:

- `P_look(1) = 1` (первую полку всегда видим);
- далее `P_look(i)` выражается через:
  - вероятность продолжить просмотр с предыдущей полки;
  - вероятность остановиться или уйти раньше.

Обозначим:

- `P_look(k) = P(пользователь дошёл до полки k)`.

### 3.2. Наблюдаемые исходы (эмиссии HMM) на полке

На каждой полке `i` пользователь может сделать один из 9 исходов.

**Переход на следующую полку:**

- `O1`: выйти из карточки `(i, 0)` в карточку `(i+1, 0)`;
- `O2`: выйти из карточки `(i, 0)` в карточку `(i+1, 1)`;
- `O3`: выйти из карточки `(i, 1)` в карточку `(i+1, 1)`;
- `O4`: выйти из карточки `(i, 1)` в карточку `(i+1, 0)`.

**Остановка на текущей полке:**

- `O5`: при заходе в карточку `(i, 0)` остановиться в карточке `(i, 0)`;
- `O6`: при заходе в карточку `(i, 0)` остановиться в карточке `(i, 1)`;
- `O7`: при заходе в карточку `(i, 1)` остановиться в карточке `(i, 1)`;
- `O8`: при заходе в карточку `(i, 1)` остановиться в карточке `(i, 0)`.

**Поглощающее состояние:**

- `O9`: мёртвое состояние без ходов — пользователь покидает выдачу (выход).

По сути:

- скрытый уровень: какие полки просматриваются;
- наблюдаемый уровень: как пользователь перемещается между карточками и полками.

### 3.3. Правила и ограничения поведения (бизнес-логика)

В модель зашиваются следующие условия:

- Если карточка релевантна, то пользователь её однозначно покупает  
  (в простейшей версии — вероятность остановки на релевантной карточке близка к 1, как только до неё дошли).
- Если карточка нерелевантна, то при её просмотре считаем вероятности:
  - `P(exit)` — выйти из выдачи;
  - `P(down/up)` — перейти между карточками на полке (между `(i, 0)` и `(i, 1)`);
  - `P(right)` — перейти на следующую полку `(i+1)`.

Эти вероятности встраиваются в распределения по исходам O<sub>1</sub>…O<sub>9</sub> как функции от релевантности карточек на полке.

**Задачи блока:**

- Формально задать:
  - множество скрытых состояний (полки);
  - множество наблюдаемых исходов O<sub>1</sub>…O<sub>9</sub>.
- Задать параметризацию:
  - как вероятности исходов зависят от релевантности карточек и их расположения;
  - как из них вычисляется `P_look(i)`.
- Описать рекурсивную формулу для `P_look(i)` через `P_look(i-1)` и вероятность «продолжить просмотр» с полки `i-1`.

---

## 4. `P_look` и метрика `PFound`

### 4.1. Расчёт `P_look(i)`

Общая идея:

$$
P_{\text{look}}(i) = \prod_{k=1}^{i-1} P_{\text{continue}}(k)
$$

$$
P_{\text{look}}(2) = P_{\text{look}}(1)\,P_{\text{continue}}(1)
$$

$$
P_{\text{look}}(3) = P_{\text{look}}(2)\*P_{\text{continue}}(2)
= P_{\text{look}}(1)\*P_{\text{continue}}(1)\*P_{\text{continue}}(2)
$$

- $P_{\text{look}}(1) = 1, \qquad$ 

Для `i > 1`:

- $P_{\text{look}}(i+1) = P_{\text{look}}(i)\*P_{\text{continue}}(i)$,

где `P_continue(i)` — вероятность того, что на полке `i` пользователь не остановился и не ушёл, а перешёл к полке `i+1`.

`P_continue(i)` выражается через вероятности исходов `O1…O4` на полке `i`.

$P_{\text{continue}}(i) = P(O_1 \mid i) + P(O_2 \mid i) + P(O_3 \mid i) + P(O_4 \mid i)$

### 4.2. Вероятности остановки на карточках

Для каждой полки `i` и позиции `pos ∈ {0,1}`:

- `P_stop(i, pos)` — вероятность того, что пользователь остановится на карточке `(i, pos)`.

Эта величина выражается через:

- `P_look(i)` — вероятность дойти до полки `i`;
- вероятности исходов `O5…O8` (локально, внутри полки).

$P_{\text{stop}}(i) = P(O_5 \mid i) + P(O_6 \mid i) + P(O_7 \mid i) + P(O_8 \mid i)$


**ИТОГО**

$$
P_{\text{continue}}(i) + P_{\text{stop}}(i) + P_{\text{exit}}(i) = 1
$$

$$
P_{\text{exit}}(i) = P(O_9 \mid i)
$$

### 4.3. Формула `PFound`

Метрика `PFound` в этой постановке:

- `PFound` — это вероятность того, что пользователь “нашёл” релевантный объект в выдаче, с учётом:
  - релевантностей карточек;
  - `P_look(i)`;
  - вероятности остановки на полке и на конкретной карточке.

Идея формулы:

- пусть `relevance_{i,pos}` — релевантность карточки `(i,pos)`,
- `gain(relevance)` — функция полезности релевантности (например, 0/1 или более гладкая).

Тогда:

$$
\text{PFound} = \sum_{i=1}^{N} \sum_{pos \in \{0,1\}}
P_{\text{stop}}(i, pos)\*\text{gain}\big(\text{relevance}_{i,pos}\big)
$$



**Задачи блока:**

- Формально записать:
  - рекуррентные формулы для `P_look(i)`;
  - выражения для `P_stop(i,pos)` через `P_look(i)` и исходы `O5…O8`.
- Выписать явную формулу `PFound`.
- Реализовать в коде:
  - функцию `compute_p_look(query_layout, params)`;
  - функцию `compute_pfound(query_layout, relevance, params)`.

---

## 5. Синтетика (генерация данных)

### 5.1. Генерация query (геометрия)

Нужно реализовать модуль генерации запросов:

- задать распределение длины выдачи `N` (количество полок);
- для каждого `query`:
  - сгенерировать `N` полок;
  - на каждой полке разместить 2 карточки `(i, 0)` и `(i, 1)`.

### 5.2. Генерация релевантности и признаков

1. **Ручные правила:**

   - задать распределение релевантности  
     (например, дискретные уровни `{0, 1, 2, 3}`);
   - задать зависимость клика/покупки от релевантности:
     - `P(click | relevance)`;
     - `P(purchase | relevance)`.

2. **Генерация признаков:**

   - `color` — по категориальному распределению;
   - `text` — простые шаблонные тексты/токены (на первом этапе),  
     с возможностью позже заменить на настоящие тексты из Amazon.

### 5.3. Генерация траекторий пользователя (по HMM)

Используя заданные параметры:

- симулировать последовательность:
  - `полка_1 → полка_2 → ...` или выход;
- на каждой полке выбирать исход O<sub>1</sub>…O<sub>9</sub>.

По траектории:

- фиксировать просмотренные полки;
- карточку, на которой пользователь остановился (если остановился);
- логи кликов и покупок.

**Задачи блока:**

- Реализовать:
  - `generate_query()` — генерация одной выдачи;
  - `generate_synthetic_dataset(num_queries, params)`.
- Реализовать симулятор поведения:
  - `simulate_user_session(query, params) → траектория + клики/покупки`.
- Сохранить синтетические данные в удобном формате (`csv` / `parquet`).

---

## 6. ML/DL-модель релевантности

### 6.1. Приведение Amazon-датасета к общей структуре

**Задачи:**

- Выбрать датасет (например, Amazon Review Data).
- Привести его к формату:
  - текст карточки (title / description);
  - таргет — proxy релевантности (рейтинг, вероятность покупки и т.п.).
- Сделать маппинг к нашей структуре:
  - каждая запись — «карточка»;
  - при необходимости группировка по `query`;
  - признаки: текст + дополнительные фичи.

### 6.2. Обучение модели релевантности

Построить модель, которая на вход получает признаки карточки и выдаёт:

- `rel_model(card)` — числовой скор релевантности.

На первом этапе:

- простой baseline:
  - логистическая регрессия или градиентный бустинг.

Далее:

- простая нейросеть или текстовая модель  
  (например, BERT-эмбеддинги + MLP).

### 6.3. Встраивание модели в синтетику

- Заменить ручные релевантности на предсказания модели.
- Перегенерировать:
  - логи поведения;
  - значения `PFound` для различных раскладок.

**Задачи блока:**

- Реализовать пайплайн:
  - загрузка и подготовка Amazon-данных;
  - обучение модели;
  - сохранение модели.
- Реализовать функцию:
  - `predict_relevance(cards)` → добавляет поле `relevance_model`.
- Сравнить:
  - `PFound` на ручной разметке;
  - `PFound` на модельной релевантности.

---

## 7. Оценка параметров HMM (EM / Baum–Welch, Витерби)

Этот блок можно оставить как продвинутый этап.

### 7.1. EM / Baum–Welch

Используя симулированные (или реальные) логи:

- оценивать:
  - вероятности исходов `O1…O9`;
  - вероятности переходов «полка → полка» / «полка → выход».

Цель: восстановить параметры так, чтобы HMM лучше описывала наблюдаемые траектории.

### 7.2. Витерби

- Восстанавливать наиболее вероятную последовательность скрытых состояний (просматриваемых полок) по наблюдаемым событиям.
- Использовать это для интерпретации и отладки HMM.

**Задачи блока:**

- Реализовать:
  - `fit_hmm_em(logs)` — оценка параметров по данным;
  - `viterbi_decode(log)` — восстановление скрытой последовательности полок.
- Сравнить восстановленные параметры с истинными (в синтетике).

---

## 8. План экспериментов

- **Baseline:**
  - ручная релевантность;
  - фиксированные параметры HMM;
  - посчитать `PFound` для разных раскладок карточек.

- **Влияние ранжирования:**
  - перетасовывать карточки по полкам;
  - смотреть, как меняется `PFound`.

- **Влияние модели релевантности:**
  - подставить `rel_model` вместо ручной релевантности;
  - сравнить `PFound` до и после.

- **Восстановление параметров:**
  - сгенерировать логи с известными параметрами;
  - попытаться восстановить их через EM;
  - оценить качество восстановления.
  - 
